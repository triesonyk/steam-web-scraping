# Webscraping Games Data From Steam

So, this is my first project on github, yay! I will tell you a little bit about why did I build this project. The dataset that was scraped from this project will be use on my future project

## Why webscraping?

I want to be a Data Analyst or Data Scientist, both of them works with Data (hence the name, lol). To attract possible employer I need to make a good porfolios, obviously. But I want to make projects or portfolios that is at least unique and difference from the others, that is why I need unique dataset to analyzed. How can I get a unique dataset? By collecting the data by myself. Besides that, having new skill (web scraping) is always nice and maybe I can use it for other purposes on the future

## Games? Really?

Okay, a lot of people in my country think that video games is just some sort of entertainment for kids. But, I myself think there is more to this than that. I've been following the industry of video games since I was in High School and the way I see it, gaming industry is one of the biggest industry (money wise). We also have to see how video game companies use and push the boundary of technology to make better games. Another personal reason is for the last decade, the gaming industry growth in my country Indonesia has been increasing at an exponential rate.  We've seen a lot of high quality games made by indie developer, such as Mojiken, Toge Production, Agate and Digital Hapiness. I want to help them grow into bigger developer and publisher. That is why I create portfolios about gaming, it is close to me and maybe it will give an impact to the gaming industry in Indonesia

## Tools

- Python : programming language
- Scrapy : python library
- VS Code : source-code editor
- Google Chrome : internet browser to inspect elements of the website 

## My Simple Webscraping Step

1. Create scaffold (default folders for web scraping) using Scrapy in Terminal 
2. Generate spider (default python script for web scraping) with Steam URL in Terminal
3. Open Steam website from Chrome
    - Disable Java Script
    - Inspect elements that we want to scrape, copy the xpath expression or css selector
4. Using xpath expression that we have copied, we can make python script to yield the data that we want
5. Using terminal do trial for the python script that we made, limit it to 100 data/rows
6. Examine the data that we scrape using csv/json if necessary make a function to clean scraped data 
7. If the website we want to scrape have pagination we have to add pagination script 
8. Export the data to csv/json or any other format

## Thank you!

Programming, data, statistics, insight, business, all of these are new to me (I started learning about Data Science on January 2022), so I would appreciate it if anybody who has tips, comments or anything can share their thoughts on my current and future projects.
